{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time, gc\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.args import init_args, add_argument_base\n",
    "from utils.initialization import *\n",
    "from utils.example import Example\n",
    "from utils.batch import from_example_list\n",
    "from utils.vocab import PAD\n",
    "from model.slu_baseline_tagging import SLUTagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    import argparse\n",
    "    arg_parser = argparse.ArgumentParser()\n",
    "\n",
    "    #### General configuration ####\n",
    "    # arg_parser.add_argument('--dataroot', default='./data', help='root of data')\n",
    "    arg_parser.add_argument('--dataroot', default='../data', help='root of data')\n",
    "    arg_parser.add_argument('--word2vec_path', default='../word2vec-768.txt', help='path of word2vector file path')\n",
    "    arg_parser.add_argument('--seed', default=999, type=int, help='Random seed')\n",
    "    arg_parser.add_argument('--device', type=int, default=-1, help='Use which device: -1 -> cpu ; the index of gpu o.w.')\n",
    "    arg_parser.add_argument('--testing', action='store_true', help='training or evaluation mode')\n",
    "    #### Training Hyperparams ####\n",
    "    arg_parser.add_argument('--batch_size', default=32, type=int, help='Batch size')\n",
    "    arg_parser.add_argument('--lr', type=float, default=1e-3, help='learning rate')\n",
    "    arg_parser.add_argument('--max_epoch', type=int, default=100, help='terminate after maximum epochs')\n",
    "    #### Common Encoder Hyperparams ####\n",
    "    arg_parser.add_argument('--encoder_cell', default='LSTM', choices=['LSTM', 'GRU', 'RNN'], help='root of data')\n",
    "    arg_parser.add_argument('--dropout', type=float, default=0.2, help='feature dropout rate')\n",
    "    arg_parser.add_argument('--embed_size', default=768, type=int, help='Size of word embeddings')\n",
    "    arg_parser.add_argument('--hidden_size', default=512, type=int, help='hidden size')\n",
    "    arg_parser.add_argument('--num_layer', default=2, type=int, help='number of layer')\n",
    "\n",
    "    args = arg_parser.parse_args([])\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def set_optimizer(model, args):\n",
    "    params = [(n, p) for n, p in model.named_parameters() if p.requires_grad]\n",
    "    grouped_params = [{'params': list(set([p for n, p in params]))}]\n",
    "    optimizer = Adam(grouped_params, lr=args.lr)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def decode(choice):\n",
    "    assert choice in ['train', 'dev']\n",
    "    model.eval()\n",
    "    dataset = train_dataset if choice == 'train' else dev_dataset\n",
    "    predictions, labels = [], []\n",
    "    total_loss, count = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(dataset), args.batch_size):\n",
    "            cur_dataset = dataset[i: i + args.batch_size]\n",
    "            current_batch = from_example_list(args, cur_dataset, device, train=True)\n",
    "            pred, label, loss = model.decode(Example.label_vocab, current_batch)\n",
    "            predictions.extend(pred)\n",
    "            labels.extend(label)\n",
    "            total_loss += loss\n",
    "            count += 1\n",
    "        metrics = Example.evaluator.acc(predictions, labels)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return metrics, total_loss / count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "set_random_seed(args.seed)\n",
    "device = set_torch_device(args.device)\n",
    "print(\"Initialization finished ...\")\n",
    "print(\"Random seed is set to %d\" % (args.seed))\n",
    "print(\"Use GPU with index %s\" % (args.device) if args.device >= 0 else \"Use CPU as target torch device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "train_path = os.path.join(args.dataroot, 'train.json')\n",
    "dev_path = os.path.join(args.dataroot, 'development.json')\n",
    "Example.configuration(args.dataroot, train_path=train_path, word2vec_path=args.word2vec_path)\n",
    "train_dataset = Example.load_dataset(train_path)\n",
    "dev_dataset = Example.load_dataset(dev_path)\n",
    "\n",
    "print(\"Load dataset and database finished, cost %.4fs ...\" % (time.time() - start_time))\n",
    "print(\"Dataset size: train -> %d ; dev -> %d\" % (len(train_dataset), len(dev_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = train_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [], '第二个到塔季他这个道士观')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.tag_id, d.slotvalue, d.utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utt_id': 1,\n",
       " 'manual_transcript': '(side)(dialect)',\n",
       " 'asr_1best': '第二个到塔季他这个道士观',\n",
       " 'semantic': []}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3865088/1225705723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_idx\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3865088/1225705723.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_idx\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "[ d.utt[idx-1] for idx in d.input_idx ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 29, 30, 31, 32, 33, 34, 35, 30, 36, 37, 38]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.input_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Example.label_vocab.num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'O',\n",
       " 'B-inform-poi名称',\n",
       " 'I-inform-poi名称',\n",
       " 'B-inform-poi修饰',\n",
       " 'I-inform-poi修饰',\n",
       " 'B-inform-poi目标',\n",
       " 'I-inform-poi目标',\n",
       " 'B-inform-起点名称',\n",
       " 'I-inform-起点名称',\n",
       " 'B-inform-起点修饰',\n",
       " 'I-inform-起点修饰',\n",
       " 'B-inform-起点目标',\n",
       " 'I-inform-起点目标',\n",
       " 'B-inform-终点名称',\n",
       " 'I-inform-终点名称',\n",
       " 'B-inform-终点修饰',\n",
       " 'I-inform-终点修饰',\n",
       " 'B-inform-终点目标',\n",
       " 'I-inform-终点目标',\n",
       " 'B-inform-途经点名称',\n",
       " 'I-inform-途经点名称',\n",
       " 'B-inform-请求类型',\n",
       " 'I-inform-请求类型',\n",
       " 'B-inform-出行方式',\n",
       " 'I-inform-出行方式',\n",
       " 'B-inform-路线偏好',\n",
       " 'I-inform-路线偏好',\n",
       " 'B-inform-对象',\n",
       " 'I-inform-对象',\n",
       " 'B-inform-操作',\n",
       " 'I-inform-操作',\n",
       " 'B-inform-序列号',\n",
       " 'I-inform-序列号',\n",
       " 'B-inform-页码',\n",
       " 'I-inform-页码',\n",
       " 'B-inform-value',\n",
       " 'I-inform-value',\n",
       " 'B-deny-poi名称',\n",
       " 'I-deny-poi名称',\n",
       " 'B-deny-poi修饰',\n",
       " 'I-deny-poi修饰',\n",
       " 'B-deny-poi目标',\n",
       " 'I-deny-poi目标',\n",
       " 'B-deny-起点名称',\n",
       " 'I-deny-起点名称',\n",
       " 'B-deny-起点修饰',\n",
       " 'I-deny-起点修饰',\n",
       " 'B-deny-起点目标',\n",
       " 'I-deny-起点目标',\n",
       " 'B-deny-终点名称',\n",
       " 'I-deny-终点名称',\n",
       " 'B-deny-终点修饰',\n",
       " 'I-deny-终点修饰',\n",
       " 'B-deny-终点目标',\n",
       " 'I-deny-终点目标',\n",
       " 'B-deny-途经点名称',\n",
       " 'I-deny-途经点名称',\n",
       " 'B-deny-请求类型',\n",
       " 'I-deny-请求类型',\n",
       " 'B-deny-出行方式',\n",
       " 'I-deny-出行方式',\n",
       " 'B-deny-路线偏好',\n",
       " 'I-deny-路线偏好',\n",
       " 'B-deny-对象',\n",
       " 'I-deny-对象',\n",
       " 'B-deny-操作',\n",
       " 'I-deny-操作',\n",
       " 'B-deny-序列号',\n",
       " 'I-deny-序列号',\n",
       " 'B-deny-页码',\n",
       " 'I-deny-页码',\n",
       " 'B-deny-value',\n",
       " 'I-deny-value']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[Example.label_vocab.idx2tag[idx] for idx in range(Example.label_vocab.num_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.vocab_size = Example.word_vocab.vocab_size\n",
    "args.pad_idx = Example.word_vocab[PAD]\n",
    "args.num_tags = Example.label_vocab.num_tags\n",
    "args.tag_pad_idx = Example.label_vocab.convert_tag_to_idx(PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SLUTagging(args).to(device)\n",
    "Example.word2vec.load_embeddings(model.word_embed, Example.word_vocab, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not args.testing:\n",
    "num_training_steps = ((len(train_dataset) + args.batch_size - 1) // args.batch_size) * args.max_epoch\n",
    "print('Total training steps: %d' % (num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = set_optimizer(model, args)\n",
    "nsamples, best_result = len(train_dataset), {'dev_acc': 0., 'dev_f1': 0.}\n",
    "train_index, step_size = np.arange(nsamples), args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start training ......')\n",
    "# for i in range(args.max_epoch):\n",
    "i = 0\n",
    "start_time = time.time()\n",
    "epoch_loss = 0\n",
    "np.random.shuffle(train_index)\n",
    "model.train()\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(0, nsamples, step_size):\n",
    "j = 0\n",
    "cur_dataset = [train_dataset[k] for k in train_index[j: j + step_size]]\n",
    "current_batch = from_example_list(args, cur_dataset, device, train=True)\n",
    "output, loss = model(current_batch)\n",
    "epoch_loss += loss.item()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = current_batch\n",
    "tag_ids = batch.tag_ids\n",
    "tag_mask = batch.tag_mask\n",
    "input_ids = batch.input_ids\n",
    "lengths = batch.lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Example.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_ids[0], tag_mask[0], input_ids[0], lengths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_ids.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "576 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.word_embed(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_inputs = rnn_utils.pack_padded_sequence(embed, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_rnn_out, h_t_c_t = model.rnn(packed_inputs)  # bsize x seqlen x dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_out, unpacked_len = rnn_utils.pad_packed_sequence(packed_rnn_out, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = model.dropout_layer(rnn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_output = model.output_layer(hiddens, tag_mask, tag_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, loss = tag_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training: \\tEpoch: %d\\tTime: %.4f\\tTraining Loss: %.4f' % (i, time.time() - start_time, epoch_loss / count))\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "metrics, dev_loss = decode('dev')\n",
    "dev_acc, dev_fscore = metrics['acc'], metrics['fscore']\n",
    "print('Evaluation: \\tEpoch: %d\\tTime: %.4f\\tDev acc: %.2f\\tDev fscore(p/r/f): (%.2f/%.2f/%.2f)' % (i, time.time() - start_time, dev_acc, dev_fscore['precision'], dev_fscore['recall'], dev_fscore['fscore']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev_acc > best_result['dev_acc']:\n",
    "    best_result['dev_loss'], best_result['dev_acc'], best_result['dev_f1'], best_result['iter'] = dev_loss, dev_acc, dev_fscore, i\n",
    "    torch.save({\n",
    "        'epoch': i, 'model': model.state_dict(),\n",
    "        'optim': optimizer.state_dict(),\n",
    "    }, open('model.bin', 'wb'))\n",
    "    print('NEW BEST MODEL: \\tEpoch: %d\\tDev loss: %.4f\\tDev acc: %.2f\\tDev fscore(p/r/f): (%.2f/%.2f/%.2f)' % (i, dev_loss, dev_acc, dev_fscore['precision'], dev_fscore['recall'], dev_fscore['fscore']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FINAL BEST RESULT: \\tEpoch: %d\\tDev loss: %.4f\\tDev acc: %.4f\\tDev fscore(p/r/f): (%.4f/%.4f/%.4f)' % (best_result['iter'], best_result['dev_loss'], best_result['dev_acc'], best_result['dev_f1']['precision'], best_result['dev_f1']['recall'], best_result['dev_f1']['fscore']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BernNetEnv",
   "language": "python",
   "name": "bernnetenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
