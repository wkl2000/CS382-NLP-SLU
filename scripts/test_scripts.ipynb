{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time, gc\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.args import init_args, add_argument_base\n",
    "from utils.initialization import *\n",
    "from utils.example import Example\n",
    "from utils.batch import from_example_list\n",
    "from utils.vocab import PAD\n",
    "from model.slu_baseline_tagging import SLUTagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    import argparse\n",
    "    arg_parser = argparse.ArgumentParser()\n",
    "    #### General configuration ####\n",
    "    arg_parser.add_argument('--dataroot', default='../data', help='root of data')\n",
    "    arg_parser.add_argument('--word2vec_path', default='../word2vec-768.txt', help='path of word2vector file path')\n",
    "    arg_parser.add_argument('--seed', default=999, type=int, help='Random seed')\n",
    "    arg_parser.add_argument('--device', type=int, default=-1, help='Use which device: -1 -> cpu ; the index of gpu o.w.')\n",
    "    arg_parser.add_argument('--testing', action='store_true', help='training or evaluation mode')\n",
    "\n",
    "    arg_parser.add_argument('--eval_interval', default=10, type=int, help='number of intervals to evaluate')\n",
    "    arg_parser.add_argument('--restore', action='store_true', help='restore training if a checkpoint exists.')\n",
    "    arg_parser.add_argument('--checkpoint_interval', default=10, type=int, help='number of intervals to save a checkpoint')\n",
    "    arg_parser.add_argument('--checkpoint_dir', default='./checkpoint.bin', help='path of checkpoint of model')\n",
    "    arg_parser.add_argument('--best_model_dir', default='./model.bin', help='path of best model')\n",
    "\n",
    "    arg_parser.add_argument('--trainset_spoken_language_select', default='both', choices=['manual_transcript', 'asr_1best', 'both'], \n",
    "                            help='sentence used for trainset(asr_1best: with noise; manual_transcript: without noise)')\n",
    "    arg_parser.add_argument('--trainset_augmentation', action='store_true', help='used augmented data from lexicon')\n",
    "\n",
    "    #### Training Hyperparams ####\n",
    "    arg_parser.add_argument('--batch_size', default=32, type=int, help='Batch size')\n",
    "    arg_parser.add_argument('--lr', type=float, default=1e-3, help='learning rate')\n",
    "    arg_parser.add_argument('--max_epoch', type=int, default=100, help='terminate after maximum epochs')\n",
    "    #### Common Encoder Hyperparams ####\n",
    "    arg_parser.add_argument('--encoder_cell', default='LSTM', choices=['LSTM', 'GRU', 'RNN'], help='root of data')\n",
    "    arg_parser.add_argument('--dropout', type=float, default=0.2, help='feature dropout rate')\n",
    "    arg_parser.add_argument('--embed_size', default=768, type=int, help='Size of word embeddings')\n",
    "    arg_parser.add_argument('--hidden_size', default=512, type=int, help='hidden size')\n",
    "    arg_parser.add_argument('--num_layer', default=2, type=int, help='number of layer')\n",
    "\n",
    "    args = arg_parser.parse_args([])\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def set_optimizer(model, args):\n",
    "    params = [(n, p) for n, p in model.named_parameters() if p.requires_grad]\n",
    "    grouped_params = [{'params': list(set([p for n, p in params]))}]\n",
    "    optimizer = Adam(grouped_params, lr=args.lr)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def decode(choice):\n",
    "    assert choice in ['train', 'dev']\n",
    "    model.eval()\n",
    "    dataset = train_dataset if choice == 'train' else dev_dataset\n",
    "    predictions, labels = [], []\n",
    "    total_loss, count = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(dataset), args.batch_size):\n",
    "            cur_dataset = dataset[i: i + args.batch_size]\n",
    "            current_batch = from_example_list(args, cur_dataset, device, train=True)\n",
    "            pred, label, loss = model.decode(Example.label_vocab, current_batch)\n",
    "            predictions.extend(pred)\n",
    "            labels.extend(label)\n",
    "            total_loss += loss\n",
    "            count += 1\n",
    "        metrics = Example.evaluator.acc(predictions, labels)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return metrics, total_loss / count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization finished ...\n",
      "Random seed is set to 999\n",
      "Use CPU as target torch device\n"
     ]
    }
   ],
   "source": [
    "# initialization params, output path, logger, random seed and torch.device\n",
    "args = get_args()\n",
    "set_random_seed(args.seed)\n",
    "device = set_torch_device(args.device)\n",
    "print(\"Initialization finished ...\")\n",
    "print(\"Random seed is set to %d\" % (args.seed))\n",
    "print(\"Use GPU with index %s\" % (args.device) if args.device >= 0 else \"Use CPU as target torch device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load configuration\n",
    "start_time = time.time()\n",
    "train_path = os.path.join(args.dataroot, 'train.json')\n",
    "dev_path = os.path.join(args.dataroot, 'development.json')\n",
    "ontology_path = os.path.join(args.dataroot, 'ontology.json')\n",
    "word2vec_path = args.word2vec_path\n",
    "if args.trainset_spoken_language_select == \"both\":\n",
    "    args.trainset_spoken_language_select = ['asr_1best', 'manual_transcript']\n",
    "if args.trainset_augmentation:\n",
    "    aug_path = os.path.join(args.dataroot, 'augmentation.json')\n",
    "    vocab_path = [train_path, aug_path]\n",
    "else:\n",
    "    vocab_path = train_path\n",
    "Example.configuration(  vocab_path=vocab_path, \n",
    "                        ontology_path=ontology_path, \n",
    "                        word2vec_path=word2vec_path,\n",
    "                        spoken_language_select=args.trainset_spoken_language_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset and database finished, cost 22.5437s ...\n",
      "Dataset size: train -> 5093 ; dev -> 921\n"
     ]
    }
   ],
   "source": [
    "# load dataset and preprocessing\n",
    "# train_dataset = Example.load_dataset(train_path)\n",
    "train_dataset = Example.load_dataset(train_path, spoken_language_select=args.trainset_spoken_language_select)\n",
    "dev_dataset = Example.load_dataset(dev_path, spoken_language_select='asr_1best')\n",
    "print(\"Load dataset and database finished, cost %.4fs ...\" % (time.time() - start_time))\n",
    "print(\"Dataset size: train -> %d ; dev -> %d\" % (len(train_dataset), len(dev_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asr_1best', 'manual_transcript']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# args.trainset_spoken_language_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = train_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab seq: 第二个到塔季他这个道士观\n",
      "tag seq: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "vocab seq(index): [28, 29, 30, 31, 32, 33, 34, 35, 30, 36, 37, 38]\n",
      "tag seq(index): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(d)\n",
    "# d.utt, d.tags, d.input_idx, d.tag_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example.label_vocab.num_tags\n",
    "# [Example.label_vocab.idx2tag[idx] for idx in range(Example.label_vocab.num_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.vocab_size = Example.word_vocab.vocab_size\n",
    "args.pad_idx = Example.word_vocab[PAD]\n",
    "args.num_tags = Example.label_vocab.num_tags\n",
    "args.tag_pad_idx = Example.label_vocab.convert_tag_to_idx(PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SLUTagging(args).to(device)\n",
    "Example.word2vec.load_embeddings(model.word_embed, Example.word_vocab, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 16000\n"
     ]
    }
   ],
   "source": [
    "# if not args.testing:\n",
    "num_training_steps = ((len(train_dataset) + args.batch_size - 1) // args.batch_size) * args.max_epoch\n",
    "print('Total training steps: %d' % (num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = set_optimizer(model, args)\n",
    "nsamples, best_result = len(train_dataset), {'dev_acc': 0., 'dev_f1': 0.}\n",
    "train_index, step_size = np.arange(nsamples), args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ......\n"
     ]
    }
   ],
   "source": [
    "print('Start training ......')\n",
    "# for i in range(args.max_epoch):\n",
    "i = 0\n",
    "start_time = time.time()\n",
    "epoch_loss = 0\n",
    "np.random.shuffle(train_index)\n",
    "model.train()\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(0, nsamples, step_size):\n",
    "j = 0\n",
    "cur_dataset = [train_dataset[k] for k in train_index[j: j + step_size]]\n",
    "current_batch = from_example_list(args, cur_dataset, device, train=True)\n",
    "output, loss = model(current_batch)\n",
    "epoch_loss += loss.item()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = current_batch\n",
    "tag_ids = batch.tag_ids\n",
    "tag_mask = batch.tag_mask\n",
    "input_ids = batch.input_ids\n",
    "lengths = batch.lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([30, 31,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]),\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " tensor([   2,    3,   31,  738,  739,   43,  240,  146,  295,  146,  452, 1592,\n",
       "          166,   45,  150,  543,  214,  243]),\n",
       " 18)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag_ids 即 decoder 的目标输出序列\n",
    "# tag_mask 用于 mask\n",
    "# input_ids 即 encoder 的原始输入序列 (可以选择 'manual_transcript' 或者 'asr_1best')\n",
    "# lengths 代表序列长度, 用于后续的 packed/unpacked\n",
    "tag_ids[0], tag_mask[0], input_ids[0], lengths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_ids.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.word_embed(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(1782, 768, padding_idx=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_inputs = rnn_utils.pack_padded_sequence(embed, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.1083,  0.1150,  0.0218,  ..., -0.1097, -0.1615, -0.1442],\n",
       "        [-0.2747,  0.1889, -0.1823,  ...,  0.2990, -0.0975,  0.0018],\n",
       "        [-0.0882, -0.2366,  0.0060,  ..., -0.3304,  0.0540,  0.1205],\n",
       "        ...,\n",
       "        [ 0.0077, -0.0665,  0.0695,  ..., -0.1178, -0.2373, -0.0091],\n",
       "        [-0.1475, -0.0168, -0.1360,  ...,  0.0174,  0.2907,  0.1095],\n",
       "        [-0.0512,  0.1464,  0.2309,  ..., -0.0013, -0.2137,  0.0770]],\n",
       "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([32, 32, 27, 27, 20, 18, 12, 11,  8,  6,  3,  2,  1,  1,  1,  1,  1,  1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 18, 768])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape     # bsize x seqlen x dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_rnn_out, h_t_c_t = model.rnn(packed_inputs)  # bsize x seqlen x dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_out, unpacked_len = rnn_utils.pad_packed_sequence(packed_rnn_out, batch_first=True)\n",
    "    # batch_first=True 即 batch 放于第一个维度 (第 0 维)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([4, 32, 256]), torch.Size([4, 32, 256]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h_t_c_t), h_t_c_t[0].shape, h_t_c_t[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 18, 512])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = model.dropout_layer(rnn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_output = model.output_layer(hiddens, tag_mask, tag_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, loss = tag_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 18, 74])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.2095, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \tEpoch: 0\tTime: 1150.2762\tTraining Loss: 4.2954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training: \\tEpoch: %d\\tTime: %.4f\\tTraining Loss: %.4f' % (i, time.time() - start_time, epoch_loss / count))\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: \tEpoch: 0\tTime: 0.5854\tDev acc: 22.48\tDev fscore(p/r/f): (0.00/0.00/0.00)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "metrics, dev_loss = decode('dev')\n",
    "dev_acc, dev_fscore = metrics['acc'], metrics['fscore']\n",
    "print('Evaluation: \\tEpoch: %d\\tTime: %.4f\\tDev acc: %.2f\\tDev fscore(p/r/f): (%.2f/%.2f/%.2f)' % (i, time.time() - start_time, dev_acc, dev_fscore['precision'], dev_fscore['recall'], dev_fscore['fscore']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST MODEL: \tEpoch: 0\tDev loss: 4.2128\tDev acc: 22.48\tDev fscore(p/r/f): (0.00/0.00/0.00)\n"
     ]
    }
   ],
   "source": [
    "if dev_acc > best_result['dev_acc']:\n",
    "    best_result['dev_loss'], best_result['dev_acc'], best_result['dev_f1'], best_result['iter'] = dev_loss, dev_acc, dev_fscore, i\n",
    "    # torch.save({\n",
    "    #     'epoch': i, 'model': model.state_dict(),\n",
    "    #     'optim': optimizer.state_dict(),\n",
    "    # }, open('model.bin', 'wb'))\n",
    "    print('NEW BEST MODEL: \\tEpoch: %d\\tDev loss: %.4f\\tDev acc: %.2f\\tDev fscore(p/r/f): (%.2f/%.2f/%.2f)' % (i, dev_loss, dev_acc, dev_fscore['precision'], dev_fscore['recall'], dev_fscore['fscore']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dev_acc': 22.47557003257329,\n",
       " 'dev_f1': {'precision': 0, 'recall': 0.0, 'fscore': 0},\n",
       " 'dev_loss': 4.212819411836821,\n",
       " 'iter': 0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL BEST RESULT: \tEpoch: 0\tDev loss: 4.2128\tDev acc: 22.4756\tDev fscore(p/r/f): (0.0000/0.0000/0.0000)\n"
     ]
    }
   ],
   "source": [
    "print('FINAL BEST RESULT: \\tEpoch: %d\\tDev loss: %.4f\\tDev acc: %.4f\\tDev fscore(p/r/f): (%.4f/%.4f/%.4f)' % (best_result['iter'], best_result['dev_loss'], best_result['dev_acc'], best_result['dev_f1']['precision'], best_result['dev_f1']['recall'], best_result['dev_f1']['fscore']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a2e5fe8f7377abb0c880357d950501caadaadc70382e466f87cca8953451fe4"
  },
  "kernelspec": {
   "display_name": "BernNetEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
